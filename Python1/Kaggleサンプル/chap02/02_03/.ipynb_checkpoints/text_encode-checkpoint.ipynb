{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag-of-Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "# Bag-of-Wordsを実行し変換後の行列を取得\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "# 戻り値はscipy.sparseの疎行列なので\n",
    "# これをNumPy配列に変換して出力\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語にマッピングされたインデックスを出力\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N-grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer='word',    # 単語単位のN-gramsを指定\n",
    "    ngram_range=(2, 2)) # 2-gramsにする\n",
    "# 変換後の行列を取得\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "# 戻り値はscipy.sparseの疎行列なので\n",
    "# これをNumPy配列に変換して出力\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this is': 11,\n",
       " 'is the': 3,\n",
       " 'the first': 6,\n",
       " 'first document': 2,\n",
       " 'this document': 10,\n",
       " 'document is': 1,\n",
       " 'the second': 7,\n",
       " 'second document': 5,\n",
       " 'and this': 0,\n",
       " 'the third': 8,\n",
       " 'third one': 9,\n",
       " 'is this': 4,\n",
       " 'this the': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2単語のつながりにマッピングされたインデックスを出力\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "# 変換後の行列を取得\n",
    "tf = vectorizer.fit_transform(corpus)\n",
    "tfidf = transformer.fit_transform(tf)\n",
    "# 戻り値はscipy.sparseの疎行列なので\n",
    "# これをNumPy配列に変換して出力\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "from gensim.models import word2vec\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "# 文(センテンス)ごとにリストにする\n",
    "sentence = [d.split() for d in corpus]\n",
    "# トレーニング\n",
    "model = word2vec.Word2Vec(\n",
    "    sentence,\n",
    "    size=10,     # 単語ベクトルの次元数\n",
    "    min_count=1, # n回未満登場する単語を破棄\n",
    "    window=2     # 学習に使う前後の単語数\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03591875, -0.01909131,  0.00052243, -0.02178675,  0.02444721,\n",
       "        0.01506153,  0.02261374,  0.02219924,  0.01048681, -0.03532327],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'This'をベクトルに変換\n",
    "model.wv['This']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00682613, -0.01287915, -0.03755166, -0.02067324,  0.04232879,\n",
       "        0.04784242, -0.00212903,  0.01688278, -0.01779048,  0.02457212],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'is'をベクトルに変換\n",
    "model.wv['is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 0.4736090302467346),\n",
       " ('And', 0.3979097008705139),\n",
       " ('Is', 0.3419610261917114),\n",
       " ('first', 0.2937809228897095),\n",
       " ('is', 0.23243652284145355),\n",
       " ('third', 0.22129905223846436),\n",
       " ('one.', 0.16492722928524017),\n",
       " ('second', 0.13379749655723572),\n",
       " ('document?', 0.03554658219218254),\n",
       " ('this', -0.022788207978010178)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'document'に近い単語を抽出\n",
    "model.wv.most_similar('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
