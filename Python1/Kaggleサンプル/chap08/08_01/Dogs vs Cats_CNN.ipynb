{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## このプログラムは「Dogs vs. Cats Redux: Kernels Edition」において\n",
    "## 作成したノートブックで動作します\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データとテストデータの解凍\n",
    "import os, shutil, zipfile\n",
    "\n",
    "# 解凍するzipファイル名\n",
    "data = ['train', 'test']\n",
    "\n",
    "# train.zip、test.zipをカレントディレクトリに展開\n",
    "for el in data:\n",
    "    with zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/' + el + \".zip\", \"r\") as z:\n",
    "        z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの前処理\n",
    "import pandas as pd\n",
    "\n",
    "# trainフォルダー内のファイル名を取得してfilenamesに格納\n",
    "filenames = os.listdir(\"./train\")\n",
    "# store the label for each image file\n",
    "categories = []\n",
    "\n",
    "# 訓練データのファイル名のdog.x.jpg、cat.x.jpgを使って1と0のラベルを生成\n",
    "for filename in filenames:\n",
    "    # ファイル名を分割して先頭要素(dog/cat)のみを取り出し、\n",
    "    # dogは1、catは0をラベルにしてcategoryに格納\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        # dogならラベル1として追加\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        # catならラベル0として追加\n",
    "        categories.append(0)\n",
    "\n",
    "# dfの列filenameにファイル名filenamesを格納\n",
    "# 列categoriesにラベルの値categoryを格納\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "# データフレームの先頭から5行目までを出力\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog(1)とcat(0)の総数をグラフにする\n",
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムに選んだ12枚の画像を出力する\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "# ランダムに16枚取り出す\n",
    "sample = random.sample(filenames, 16)\n",
    "\n",
    "# 描画するエリアのサイズは12×12\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(0, 16):\n",
    "    # 4×4のマス目の左上隅から順番に描画\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    # sampleに格納されたi番目の画像\n",
    "    fname = sample[i]\n",
    "    # trainフォルダーから画像を読み込む\n",
    "    image = load_img(\"./train/\"+fname)\n",
    "    # 画像を描画\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off') # 目盛りは非表示\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データを訓練用と検証用に分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練データの総数25000の10%を検証データにする\n",
    "train_df, validate_df = train_test_split(df, test_size=0.1)\n",
    "# 行インデックスを振り直す\n",
    "train_df = train_df.reset_index()\n",
    "validate_df = validate_df.reset_index()\n",
    "\n",
    "# 訓練データの数を取得\n",
    "total_train = train_df.shape[0]\n",
    "# 検証データの数を取得\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "# 訓練、検証データの数を出力\n",
    "print(total_train)\n",
    "print(total_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データを加工処理する\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 画像をリサイズするときのサイズ\n",
    "img_width, img_height = 224, 224\n",
    "target_size = (img_width, img_height)\n",
    "# ミニバッチのサイズ\n",
    "batch_size = 16\n",
    "\n",
    "# データフレームに格納したファイル名の列名とラベルの列名\n",
    "x_col, y_col = 'filename', 'category'\n",
    "# flow_from_dataframe()で画像を生成する際のclass_modeオプションの値\n",
    "# ジェネレーターが返すラベルの配列の形状として二値分類の'binary'を格納\n",
    "class_mode = 'binary'\n",
    "\n",
    "# 画像を加工するジェネレーターを生成\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,         # RGB値を0～1.0の範囲に変換\n",
    "    rotation_range=15,      # ランダムに回転\n",
    "    shear_range=0.2,        # シアー変換\n",
    "    zoom_range=0.2,         # 拡大\n",
    "    horizontal_flip=True,   # 水平方向に反転\n",
    "    width_shift_range=0.1,  # 平行移動\n",
    "    height_shift_range=0.1  # 垂直移動\n",
    ")\n",
    "\n",
    "\n",
    "# flow_from_dataframe()の引数class_mode = \"binary\"の場合、\n",
    "# ラベルが格納されたtrain_dfのy_col = 'category'の列の値は\n",
    "# 文字列であることが必要なので、1と0の数値を文字列に変換しておく\n",
    "train_df['category'] = train_df['category'].astype(str) \n",
    "\n",
    "# ジェネレータで加工した画像の生成\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,    # 訓練用のデータフレーム\n",
    "    \"./train/\",  # 画像データのディレクトリ\n",
    "    x_col=x_col, # ファイル名が格納された列\n",
    "    y_col=y_col, # ラベルが格納された列 (文字列に変換済み)\n",
    "    class_mode=class_mode, # ラベルの配列の形状\n",
    "    target_size=target_size, # 画像のサイズ\n",
    "    batch_size=batch_size    # ミニバッチのサイズ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データを加工処理する\n",
    "\n",
    "# 画像を加工するジェネレーターを生成\n",
    "# データ拡張は必要ないのでRGB値の変換のみを行う\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# flow_from_dataframe()の引数class_mode = \"binary\"の場合、\n",
    "# ラベルが格納されたvalidate_dfのy_col = 'category'の列の値は\n",
    "# 文字列であることが必要なので、1と0の数値を文字列に変換しておく\n",
    "validate_df['category'] = validate_df['category'].astype(str)\n",
    "\n",
    "# ジェネレータで加工した画像の生成\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,  # 検証用のデータフレーム\n",
    "    \"./train/\",   # 画像データのディレクトリ\n",
    "    x_col=x_col,  # ファイル名が格納された列\n",
    "    y_col=y_col,  # ラベルが格納された列(文字列に変換済み)\n",
    "    class_mode=class_mode,   # ラベルの配列の形状\n",
    "    target_size=target_size, # 画像のサイズ\n",
    "    batch_size=batch_size    # ミニバッチのサイズ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データから1サンプル取り出し、加工処理後の9パターンを表示\n",
    "\n",
    "# 訓練データから1サンプル取り出し、reset_index()でインデックスを振り直す\n",
    "# drop=Trueは元のインデックスを削除するためのもの\n",
    "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "# DataFrameIteratorオブジェクトを生成\n",
    "example_generator = train_datagen.flow_from_dataframe(\n",
    "    example_df,       # サンプルデータを格納したデータフレーム\n",
    "    \"./train/\",       # 画像データの場所\n",
    "    x_col='filename', # ファイル名の列名\n",
    "    y_col='category', # 正解ラベルの列名\n",
    "    target_size=target_size # 画像をリサイズする\n",
    ")\n",
    "# 描画エリアのサイズは12×12\n",
    "plt.figure(figsize=(12, 12))\n",
    "# 加工処理後の9パターンを表示\n",
    "for i in range(0, 9):\n",
    "    # 3×3のマス目の左上隅から順番に描画\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        # X_batchの1つ目の画像データを抽出\n",
    "        image = X_batch[0]\n",
    "        # 抽出した画像を描画したらbreakする\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3層の畳み込み層を持つCNN\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Sequentualオブジェクトを生成\n",
    "model = Sequential()\n",
    "\n",
    "# 入力データの形状\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# 第1層:畳み込み層1\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,              # フィルターの数は32\n",
    "        kernel_size=(3, 3),      # 3×3のフィルターを使用\n",
    "        padding='same',          # ゼロパディングを行う\n",
    "        activation='relu',       # 活性化関数はReLU\n",
    "        input_shape=input_shape, # 入力データの形状\n",
    "        ))\n",
    "\n",
    "# 第2層:プーリング層\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2, 2)))\n",
    "# ドロップアウト25％\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 第3層:畳み込み層2\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters = 64,        # フィルターの数は32\n",
    "        kernel_size = (3,3), # 3×3のフィルターを使用\n",
    "        padding='same',      # ゼロパディングを行う\n",
    "        activation='relu',   # 活性化関数はReLU\n",
    "        ))\n",
    "\n",
    "# 第4層:プーリング層\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2, 2)))\n",
    "# ドロップアウト25％\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 第5層:畳み込み層3\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=128,          # フィルターの数は64\n",
    "        kernel_size=(3, 3),   # 3×3のフィルターを使用\n",
    "        padding='same',       # ゼロパディングを行う\n",
    "        activation='relu',    # 活性化関数はReLU\n",
    "        ))\n",
    "\n",
    "# 第6層:プーリング層\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    ")\n",
    "# ドロップアウト25％\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (batch_size, rows, cols, channels)の4階テンソルに\n",
    "# プーリング演算適用後、(batch_size, channels)の2階テンソルにフラット化\n",
    "model.add(\n",
    "    GlobalMaxPooling2D())\n",
    "\n",
    "# 第7層\n",
    "model.add(\n",
    "    Dense(128,                   # ユニット数128\n",
    "          activation='relu'))    # 活性化関数はReLU\n",
    "# ドロップアウト25％\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 第8層:出力層\n",
    "model.add(\n",
    "    Dense(1,                     # ニューロン数は1個\n",
    "          activation='sigmoid')) # 活性化関数はSigmoid\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',    # バイナリ用のクロスエントロピー誤差\n",
    "    metrics=['accuracy'],          # 学習評価として正解率を指定\n",
    "    optimizer=optimizers.RMSprop() # RMSpropで最適化\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習を行う\n",
    "\n",
    "import math\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "\n",
    "# 学習率をスケジューリングする\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001 # 学習率の初期値\n",
    "    drop = 0.5            # 減衰率は50%\n",
    "    epochs_drop = 10.0    # 10エポック毎に減衰する\n",
    "    lrate = initial_lrate * math.pow(\n",
    "        drop,\n",
    "        math.floor((epoch)/epochs_drop)\n",
    "    )\n",
    "    return lrate\n",
    "\n",
    "# 学習率のコールバック\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    " \n",
    "# 学習の進捗を監視して早期終了するコールバック\n",
    "earstop = EarlyStopping(\n",
    "    monitor='val_loss', # 監視対象は損失\n",
    "    min_delta=0,        # 改善として判定される最小変化値\n",
    "    patience=5)         # 改善が見られないと判断されるエポック数を5に拡大\n",
    "\n",
    "\n",
    "# 学習の実行\n",
    "# GPU使用による所要時間:\n",
    "epochs = 40        # エポック数\n",
    "history = model.fit(\n",
    "    # 訓練データ\n",
    "    train_generator,\n",
    "    # エポック数\n",
    "    epochs=epochs,\n",
    "    # 訓練時のステップ数\n",
    "    steps_per_epoch = total_train//batch_size,\n",
    "    # 検証データ\n",
    "    validation_data=validation_generator,\n",
    "    # 検証時のステップ数\n",
    "    validation_steps = total_validate//batch_size,\n",
    "    # 学習の進捗状況を出力する    \n",
    "    verbose=1,\n",
    "    # 学習率のスケジューラーとアーリーストッピングをコール\n",
    "    callbacks=[lrate, earstop]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
