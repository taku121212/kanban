{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## このプログラムは「CIFAR-10 - Object Recognition in Images」において\n",
    "## 作成したノートブックで動作します\n",
    "## ローカル環境のJupyter Notebookで作成したノートブックでも動作可能です\n",
    "\n",
    "# モデルを生成する\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras        import optimizers\n",
    "\n",
    "def make_convlayer():\n",
    "    # Sequentialオブジェクト\n",
    "    model = Sequential()\n",
    "    # 畳み込み層1\n",
    "    model.add(Conv2D(\n",
    "        filters=64, kernel_size=3, padding='same',\n",
    "        activation='relu',input_shape=(32,32,3)))\n",
    "    # 2×2のプーリング層\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    # 畳み込み層2\n",
    "    model.add(Conv2D(\n",
    "        filters=128, kernel_size=3, padding='same', \n",
    "        activation='relu'))\n",
    "    # 2×2のプーリング層\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    #畳み込み層3\n",
    "    model.add(Conv2D(\n",
    "        filters=256, kernel_size=3, padding='same', \n",
    "        activation='relu'))\n",
    "    #2×2のプーリング層\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    # Flatten層\n",
    "    model.add(Flatten())\n",
    "    # ドロップアウト\n",
    "    model.add(Dropout(0.4))\n",
    "    # 第7層\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    # 出力層\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "    # オプティマイザーはAdam\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=optimizers.Adam(lr=0.001),\n",
    "                  metrics=[\"accuracy\"])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import History, LearningRateScheduler\n",
    "\n",
    "def step_decay(epoch):\n",
    "    \"\"\"1/5ずつ学習率を減衰する\n",
    "    \n",
    "    Parameters:epoch(int):エポック数\n",
    "    Returns   : 学習率\n",
    "    \"\"\"\n",
    "    lrate = 0.001\n",
    "    if epoch >= 50: lrate /= 5.0\n",
    "    if epoch >= 100: lrate /= 5.0\n",
    "    if epoch >= 150: lrate /= 5.0\n",
    "    return lrate\n",
    "\n",
    "def train_batchsize(model, data, batch_size, epochs, decay):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "      model(obj)     : Modelオブジェクト\n",
    "      data(tuple)    : 訓練データ、テストデータ\n",
    "      batch_size(int): バッチサイズ\n",
    "      epochs(int)    : エポック数\n",
    "      decay(float)   : 学習率\n",
    "    \"\"\"\n",
    "    x_train, y_train, x_test, y_test = data\n",
    "    # 訓練データ\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1.0/255.0,      # 正規化\n",
    "        width_shift_range=0.1,  # 0.1の割合でランダムに水平移動\n",
    "        height_shift_range=0.1, # 0.1の割合でランダムに垂直移動\n",
    "        rotation_range=10,      # 10度の範囲でランダムに回転させる\n",
    "        zoom_range=0.1,         # ランダムに拡大\n",
    "        horizontal_flip=True    # 左右反転\n",
    "        ).flow(x_train, y_train, batch_size=batch_size)\n",
    "    # テストデータ\n",
    "    test_gen = ImageDataGenerator(\n",
    "        rescale=1.0/255.0       # 正規化\n",
    "        ).flow(x_test, y_test, batch_size=128) # バッチサイズは128\n",
    "\n",
    "    hist = History()\n",
    "    # 学習\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=x_train.shape[0]//batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_gen,\n",
    "        callbacks=[hist, decay])\n",
    "    \n",
    "    return hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def train(train_mode):\n",
    "    \"\"\"\n",
    "    train_mode(int);\n",
    "      # 0: normal batch_size=128,\n",
    "           lr=0.001,0.0002‬, 0.00004‬, 0.000008‬\n",
    "      # 1: increase batch = 128, 640, 3200, 16000\n",
    "           lr=0.001\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    data = (x_train, y_train, x_test, y_test)\n",
    "\n",
    "    # モデル生成\n",
    "    model = make_convlayer()\n",
    "\n",
    "    # Historyオブジェクトを保持するリスト\n",
    "    histories = []\n",
    "    # 学習率減衰用のスケジューラー\n",
    "    decay = LearningRateScheduler(step_decay)\n",
    "    # 可変バッチサイズ用のスケジューラー\n",
    "    same_lr = LearningRateScheduler(lambda epoch: 0.001)\n",
    "    # 学習率減衰\n",
    "    if train_mode == 0:\n",
    "        histories.append(train_batchsize(\n",
    "                model, data, batch_size=128, epochs=200, decay=decay))\n",
    "    # バッチサイズ増加\n",
    "    if train_mode == 1:\n",
    "        histories.append(train_batchsize(\n",
    "                model, data, batch_size=128, epochs=50, decay=same_lr))\n",
    "        histories.append(train_batchsize(\n",
    "                model, data, batch_size=640, epochs=50, decay=same_lr))\n",
    "        histories.append(train_batchsize(\n",
    "                model, data, batch_size=3200, epochs=50, decay=same_lr))\n",
    "        histories.append(train_batchsize(\n",
    "                model, data, batch_size=16000, epochs=50, decay=same_lr))\n",
    "\n",
    "    # Historyの統合\n",
    "    joined_history = histories[0]\n",
    "    for i in range(1, len(histories)):\n",
    "        for key, value in histories[i].items():\n",
    "            joined_history[key] = joined_history[key] + value\n",
    "            \n",
    "    return joined_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練時の精度の推移をグラフ化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.ﬁgure(ﬁgsize=(15, 15)) # プロット図のサイズ\n",
    "plt.subplot(2, 1, 1)       # 2×1のグリッドの上部にプロット\n",
    "\n",
    "# 学習率減衰の精度をプロット\n",
    "plt.plot(\n",
    "    history['accuracy'], label='lr', color='black')\n",
    "# バッチサイズ増加の精度をプロット\n",
    "plt.plot(\n",
    "    history_batch['accuracy'], label='batch',color='red')\n",
    "plt.legend()         # 凡例表示\n",
    "plt.grid()           # グリッド表示\n",
    "plt.xlabel('Epoch')  # x軸ラベル\n",
    "plt.ylabel('Acc')    # y軸ラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データの精度の推移をグラフ化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.ﬁgure(ﬁgsize=(15, 15)) # プロット図のサイズ\n",
    "plt.subplot(2, 1, 1)       # 2×1のグリッドの上部にプロット\n",
    "\n",
    "# 学習率減衰の精度をプロット\n",
    "plt.plot(\n",
    "    history['val_accuracy'], label='lr', color='black')\n",
    "# バッチサイズ増加の精度をプロット\n",
    "plt.plot(\n",
    "    history_batch['val_accuracy'], label='batch',color='red')\n",
    "plt.legend()         # 凡例表示\n",
    "plt.grid()           # グリッド表示\n",
    "plt.xlabel('Epoch')  # x軸ラベル\n",
    "plt.ylabel('Acc')    # y軸ラベル"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
