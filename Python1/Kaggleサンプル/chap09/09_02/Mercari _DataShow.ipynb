{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## このプログラムは「Mercari Price Suggestion Challenge」において\n",
    "## 作成したノートブックで動作します\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 訓練データテストデータをデータフレームに読み込む\n",
    "train_df = pd.read_table('../input/mercari/train.tsv')\n",
    "test_df = pd.read_table('../input/mercari/test.tsv')\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　訓練データの冒頭を表示\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ドル未満のレコードをすべて削除する\n",
    "train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\n",
    "print(train_df.shape)\n",
    "print(train_df['price'].max())\n",
    "print(train_df['price'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_df['price'].hist()  # 'price'のヒストグラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['price'].hist(range=(0, 100)) # 範囲を3～100にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 訓練データのpriceを対数変換する\n",
    "train_df[\"target\"] = np.log1p(train_df.price)\n",
    "# ヒストグラムを表示\n",
    "train_df['target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ名を切り分けて新設のカラムに登録する\n",
    "\n",
    "def split_cat(text):\n",
    "    \"\"\"\n",
    "    ・カテゴリを/で切り分ける\n",
    "    ・データが存在しない場合は'No Label'を返す\n",
    "    \"\"\"\n",
    "    try: return text.split(\"/\")\n",
    "    except: return ('No Label', 'No Label', 'No Label')\n",
    "\n",
    "# 3つに切り分けたカテゴリ名を'subcat_0'、'subcat_1'、'subcat_2'に登録\n",
    "train_df['subcat_0'], train_df['subcat_1'], train_df['subcat_2'] = \\\n",
    "    zip(*train_df['category_name'].apply(lambda x: split_cat(x)))\n",
    "\n",
    "test_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] = \\\n",
    "    zip(*test_df['category_name'].apply(lambda x: split_cat(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'brand_name'の対策\n",
    "\n",
    "# train_dfとtest_dfを縦方向に結合\n",
    "full_set = pd.concat([train_df, test_df])\n",
    "# full_setの'brand_name'から重複なしのブランドリスト(集合)を生成\n",
    "all_brands = set(full_set['brand_name'].values)\n",
    "\n",
    "# 'brand_name'の欠損値NaNを'missing'に置き換える\n",
    "train_df['brand_name'].fillna(value='missing', inplace=True)\n",
    "test_df['brand_name'].fillna(value='missing', inplace=True)\n",
    "\n",
    "# 訓練データの'brand_name'が'missing'に一致するレコード数を取得\n",
    "train_premissing = len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "# テストデータの'brand_name'が'missing'に一致するレコード数を取得\n",
    "test_premissing = len(test_df.loc[test_df['brand_name'] == 'missing'])\n",
    "\n",
    "def brandfinder(line):\n",
    "    \"\"\"\n",
    "    Parameters: line(str): ブランド名\n",
    "\n",
    "    ・ブランド名の'missing'を商品名に置き換える:\n",
    "         missing'の商品名の単語がブランドリストに存在する場合\n",
    "    ・ブランド名を商品名に置き換える:\n",
    "        商品名がブランドリストの名前と完全に一致する場合\n",
    "    ・ブランド名をそのままにする:\n",
    "        商品名がブランドリストの名前と一致しない\n",
    "        商品名が'missing'だが商品名の単語がブランドリストにない\n",
    "    \"\"\"\n",
    "    brand = line[0] # 第1要素はブランド名\n",
    "    name = line[1]  # 第2要素は商品名\n",
    "    namesplit = name.split(' ') # 商品名をスペースで切り分ける\n",
    "    \n",
    "    if brand == 'missing':  # ブランド名が'missing'と一致\n",
    "        for x in namesplit: # 商品名から切り分けた単語を取り出す\n",
    "            if x in all_brands:                \n",
    "                return name # 単語がブランドリストに一致したら商品名を返す\n",
    "    if name in all_brands:  # 商品名がブランドリストに存在すれば商品名を返す\n",
    "        return name\n",
    "    \n",
    "    return brand            # どれにも一致しなければブランド名を返す\n",
    "\n",
    "# ブランド名の付替えを実施\n",
    "train_df['brand_name'] = train_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "test_df['brand_name'] = test_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "\n",
    "# 書き換えられた'missing'の数を取得\n",
    "train_found = train_premissing-len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "test_found = test_premissing-len(test_df.loc[test_df['brand_name'] == 'missing'])\n",
    "print(train_premissing) # 書き換える前の'missing'の数\n",
    "print(train_found)      # 書き換えられた'missing'の数\n",
    "print(test_premissing)  # 書き換える前の'missing'の数\n",
    "print(test_found)       # 書き換えられた'missing'の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、検証データ、テストデータを1つのデータフレームに連結\n",
    "full_df = pd.concat([train_df, test_df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連結データのカテゴリ名、ブランド名、説明文のNaNを'missing'に置き換える\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    df.category_name.fillna(value='missing', inplace=True)    # カテゴリ名\n",
    "    df.brand_name.fillna(value='missing', inplace=True)       # ブランド名\n",
    "    df.item_description.fillna(value='missing', inplace=True) # 説明文\n",
    "    # 説明文の'No description yet'を'missing'にする\n",
    "    df.item_description.replace(\n",
    "        'No description yet','missing', inplace=True) # 説明文の置き換え\n",
    "    return df\n",
    "\n",
    "full_df = fill_missing_values(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連結データのカテゴリ、ブランド、3カテゴリのテキストをラベルエンコードする\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoderの生成\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 'category_name'をエンコードして'category'カラムに登録する\n",
    "le.fit(full_df.category_name)\n",
    "full_df['category'] = le.transform(full_df.category_name)\n",
    "\n",
    "# 'brand_name'のエンコード\n",
    "le.fit(full_df.brand_name)\n",
    "full_df.brand_name = le.transform(full_df.brand_name)\n",
    "\n",
    "# 'subcat_0'のエンコード\n",
    "le.fit(full_df.subcat_0)\n",
    "full_df.subcat_0 = le.transform(full_df.subcat_0)\n",
    "\n",
    "# 'subcat_1'のエンコード\n",
    "le.fit(full_df.subcat_1)\n",
    "full_df.subcat_1 = le.transform(full_df.subcat_1)\n",
    "\n",
    "# 'subcat_2'のエンコード\n",
    "le.fit(full_df.subcat_2)\n",
    "full_df.subcat_2 = le.transform(full_df.subcat_2)\n",
    "\n",
    "del le\n",
    "\n",
    "print(full_df.category.head())   # カテゴリ名\n",
    "print(full_df.brand_name.head()) # ブランド名\n",
    "print(full_df.subcat_0.head())   # 分割した1番目のカテゴリ\n",
    "print(full_df.subcat_1.head())   # 分割した2番目のカテゴリ\n",
    "print(full_df.subcat_2.head())   # 分割した3番目のカテゴリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連結データの説明文、商品名をラベルエンコードする\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 説明文、商品名、カテゴリ名の配列要素を以下のように1次元配列に連結する\n",
    "# [[説明1,説明2, ..., 商品1,商品2, ..., カテゴリ1,カテゴリ2, ...]\n",
    "#\n",
    "print(\"Transforming text data to sequences...\")\n",
    "raw_text = np.hstack(\n",
    "    [full_df.item_description.str.lower(), # 説明文\n",
    "     full_df.name.str.lower(),             # 商品名\n",
    "     full_df.category_name.str.lower()]    # カテゴリ名\n",
    ")\n",
    "print('sequences shape', raw_text.shape)\n",
    "\n",
    "# 説明文、商品名、カテゴリ名を連結した配列でTokenizerを作る\n",
    "print(\"   Fitting tokenizer...\")\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "\n",
    "# Tokenizerで説明文、商品名をそれぞれラベルエンコードする\n",
    "print(\"   Transforming text to sequences...\")\n",
    "full_df['seq_item_description'] = tok_raw.texts_to_sequences(full_df.item_description.str.lower())\n",
    "full_df['seq_name'] = tok_raw.texts_to_sequences(full_df.name.str.lower())\n",
    "\n",
    "del tok_raw\n",
    "\n",
    "print(full_df.seq_item_description.head())\n",
    "print(full_df.seq_name.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0でパディングして配列の長さを揃える\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "print(pad_sequences(full_df.seq_item_description, maxlen=80),'\\n') # 商品説明\n",
    "print(pad_sequences(full_df.seq_name, maxlen=10))                  # 商品名"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
